# GH actions.
name: Wheel-Manylinux-Nightly


on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  schedule:
    - cron: '0 6 * * *' # 6 AM UTC

jobs:
  Build:
    strategy:
      matrix:
        pkg: ['mlc-ai-nightly']
        mlc-chat-pkg: ['mlc-chat-nightly']
        # matrix of build configs
        config:
          - cuda: 'none'
            dockerfile: 'Dockerfile.package-cpu'
          - cuda: '11.6'
            dockerfile: 'Dockerfile.package-cu116'
          - cuda: '11.7'
            dockerfile: 'Dockerfile.package-cu117'
          - cuda: '11.8'
            dockerfile: 'Dockerfile.package-cu118'
          - cuda: '12.1'
            dockerfile: 'Dockerfile.package-cu121'

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
      with:
        submodules: 'recursive'
    - name: Setup script env
      run: |
        rm -rf conda
        ln -s 3rdparty/tlcpack/conda conda
    - name: Checkout source
      run: |
        git clone https://github.com/mlc-ai/relax tvm --recursive
        git clone https://github.com/mlc-ai/mlc-llm mlc-llm --recursive
    - name: Sync Package
      run: |
        python scripts/sync_package.py --cuda ${{ matrix.config.cuda }} --package tvm --package-name ${{ matrix.pkg }} --revision origin/mlc
        python scripts/sync_package.py --cuda ${{ matrix.config.cuda }} --package mlc-llm --package-name ${{ matrix.mlc-chat-pkg }} --revision origin/main
    - name: Docker build
      run: |
        cd docker
        docker build -t mlc-ai-${{ matrix.config.cuda }} . -f ${{ matrix.config.dockerfile }}
    - name: Build TVM Unity
      env:
        IMAGE: mlc-ai-${{ matrix.config.cuda }}
        CUDA: ${{ matrix.config.cuda }}
      run: |
        docker/bash.sh --no-gpu $IMAGE ./wheel/build_wheel_manylinux.sh --cuda $CUDA
    - name: Build MLC-Chat
      env:
        IMAGE: mlc-ai-${{ matrix.config.cuda }}
        CUDA: ${{ matrix.config.cuda }}
      run: |
        docker/bash.sh --no-gpu $IMAGE ./wheel/build_mlc_chat_wheel_manylinux.sh --cuda $CUDA
    - name: MLC-Chat Wheel-Deploy
      if: github.ref == 'refs/heads/main'
      uses: softprops/action-gh-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.MLC_GITHUB_TOKEN }}
      with:
        files: |
          tvm/python/repaired_wheels/*.whl
          mlc-llm/python/repaired_wheels/*.whl
        tag_name: v0.9.dev0
        prerelease: true
