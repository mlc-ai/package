# GH actions.
name: Wheel-Manylinux-Nightly


on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  schedule:
    - cron: '0 6 * * *' # 6 AM UTC

jobs:
  Build:
    strategy:
      matrix:
        pkg_kind: ['nightly', 'stable']
        # matrix of build configs
        config:
          - gpu: 'none'
            image: 'mlcaidev/package-cpu:76cedcd'
          - gpu: 'cuda-12.2'
            image: 'mlcaidev/package-cu122:76cedcd'
          - gpu: 'cuda-12.3'
            image: 'mlcaidev/package-cu123:76cedcd'
          - gpu: 'rocm-6.1'
            image: 'mlcaidev/package-rocm61:76cedcd'
          - gpu: 'rocm-6.2'
            image: 'mlcaidev/package-rocm62:76cedcd'
        exclude:
          - pkg_kind: ${{ github.event_name == 'schedule' && 'stable' || '' }}

    runs-on: [self-hosted, Linux, X64]

    steps:
    - uses: actions/checkout@v3
      with:
        submodules: 'recursive'
    - name: Setup script env
      run: |
        rm -rf conda
        ln -s 3rdparty/tlcpack/conda conda
    - name: Checkout source
      run: |
        git clone https://github.com/mlc-ai/relax tvm --recursive
        git clone https://github.com/mlc-ai/mlc-llm mlc-llm --recursive
    - name: Sync MLC AI Package
      run: |
        python3 scripts/sync_package.py --gpu ${{ matrix.config.gpu }} --package tvm --package-name ${{ matrix.pkg_kind == 'nightly' && 'mlc-ai-nightly' || 'mlc-ai' }} --revision origin/mlc ${{ matrix.pkg_kind == 'nightly' && '--skip-checkout' || '' }} --skip-conda
    - name: Sync MLC LLM Package
      run: |
        python3 scripts/sync_package.py --gpu ${{ matrix.config.gpu }} --package mlc-llm --package-name ${{ matrix.pkg_kind == 'nightly' && 'mlc-llm-nightly' || 'mlc-llm' }} --revision origin/main ${{ matrix.pkg_kind == 'nightly' && '--skip-checkout' || '' }} --skip-conda
    - name: Build TVM Unity
      uses: gacts/run-and-post-run@v1
      env:
        IMAGE: ${{ matrix.config.image }}
        GPU: ${{ matrix.config.gpu }}
      with:
        run: |
          docker/bash.sh --no-gpu $IMAGE ./scripts/build_mlc_ai_wheel_manylinux.sh --gpu $GPU
        post: |
          docker/bash.sh --no-gpu $IMAGE ./scripts/cleanup_workspace.sh
    - name: Build MLC-LLM
      uses: gacts/run-and-post-run@v1
      env:
        IMAGE: ${{ matrix.config.image }}
        GPU: ${{ matrix.config.gpu }}
      with:
        run: |
          docker/bash.sh --no-gpu $IMAGE ./scripts/build_mlc_llm_wheel_manylinux.sh --gpu $GPU
        post: |
          docker/bash.sh --no-gpu $IMAGE ./scripts/cleanup_workspace.sh
    - name: Wheel-Deploy
      if: github.ref == 'refs/heads/main'
      uses: softprops/action-gh-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.MLC_GITHUB_TOKEN }}
      with:
        files: |
          tvm/python/repaired_wheels/*.whl
          mlc-llm/python/repaired_wheels/*.whl
        tag_name: v0.9.dev0
        prerelease: true
